---
layout: post
title: Reinforcement Learning Study 1
shorttitle: Chapter 1 and 2
date: 2021-01-26 19:20:23 +0900
category: Study 
---
# Chapter 1. Introduction
> _Reinforcement learning (RL) is learning what to do so as to maximize the numerical reward signal._

+ Two distinguishing features of RL = Trial-and-Error + Delayed Reward

> _A learning agent must be able to sense the state of its environment to some extent and must be able to take actions that affect the state. The agent also must have a goal or goals relating to the state of the environment._

```ruby
state, reward = Environment(action)
action = agent(state, reward, goal)
```

+ _RL is different from SL_: No examples of desired behavior that are both correct and representative of all the situations.

+ _RL is different from UL_: Maximizing a reward signal but not uncovering the structure.

+ Exploitation of experience vs Exploration of not selected actions

+ RL's subelememts: _policy_, _reward_, _value function_, _model_ (_planning_)


# Chapter 2. Multi-armed Bandits
> _k-armed bandit problem: You are faced repeatedly with a choice among k different options, or actions. After each choice you receive a numerical reward chosen from a stationary probability distribution that depends on the action you selected. Your objective is to maximize the expected total reward over some time period._

+ Expected Reward ($$q_{\*}$$)

$$ q_{\*}(a)=E[R_t|A_t=a] $$
